tbl_summary(oasis_f2[,-c(1,7:9)], by = 'CDR')
View(oasis_f2)
tbl_summary(oasis_f2[,c(2:5,7)], by = 'CDR')
library(mice)
install.packages("mice")
library(mice)
mice(oasis_f2, m=m, printFlag =FALSE)
?mice
mice(oasis_f2, m=5, printFlag =FALSE)
mi.oasis_f2 = mice(oasis_f2, m=5, printFlag =FALSE)
mi.temp.oasis_f2 = complete(mi.oasis_f2,"all")
mi.temp.oasis_f2
View(mi.temp.oasis_f2)
?complete
mi.temp.oasis_f2[[1]]
mi.temp.oasis_f2[[1]] == mi.temp.oasis_f2[[2]]
all(mi.temp.oasis_f2[[1]] == mi.temp.oasis_f2[[2]])
library(caret)
library(ggplot2)
library(gtsummary)
library(mice)
oasis_f = read.csv("C:/Users/xtk96/Desktop/625_final/oasis_cross-sectional_filter.csv")
oasis_f2 = oasis_f[,c(1,2,4,5,7:10)]
oasis_f2$CDR = as.factor(oasis_f2$CDR)
oasis_f2$M.F = as.factor(oasis_f2$M.F)
levels(oasis_f2$CDR) <- c("EqaulTo0", "LargeThan0")
#---------------------------------------------
# summary table
#---------------------------------------------
tbl_summary(oasis_f2[,c(2:5,7)], by = 'CDR')
mi.oasis_f2 = mice(oasis_f2, m=5, printFlag =FALSE)
mi.temp.oasis_f2 = complete(mi.oasis_f2,"all")
oasis_f3 = mi.temp.oasis_f2[[1]]
attach(oasis_f3)
calc_acc = function(actual, predicted) {
mean(actual == predicted)
}
library(caret)
library(ggplot2)
library(gtsummary)
library(mice)
oasis_f = read.csv("C:/Users/xtk96/Desktop/625_final/oasis_cross-sectional_filter.csv")
oasis_f2 = oasis_f[,c(1,2,4:10)]
oasis_f2$CDR = as.factor(oasis_f2$CDR)
oasis_f2$M.F = as.factor(oasis_f2$M.F)
levels(oasis_f2$CDR) <- c("EqaulTo0", "LargeThan0")
#---------------------------------------------
# summary table
#---------------------------------------------
tbl_summary(oasis_f2[,c(2:5,7)], by = 'CDR')
mi.oasis_f2 = mice(oasis_f2, m=5, printFlag =FALSE)
mi.temp.oasis_f2 = complete(mi.oasis_f2,"all")
oasis_f3 = mi.temp.oasis_f2[[1]]
attach(oasis_f3)
calc_acc = function(actual, predicted) {
mean(actual == predicted)
}
?sample
sample(1:5,1)
sample(1:5,1)
set.seed(123)
m = sample(1:5,1)
m
library(caret)
library(ggplot2)
library(gtsummary)
library(mice)
oasis_f = read.csv("C:/Users/xtk96/Desktop/625_final/oasis_cross-sectional_filter.csv")
oasis_f2 = oasis_f[,c(1,2,4:10)]
oasis_f2$CDR = as.factor(oasis_f2$CDR)
oasis_f2$M.F = as.factor(oasis_f2$M.F)
levels(oasis_f2$CDR) <- c("EqaulTo0", "LargeThan0")
#---------------------------------------------
# summary table
#---------------------------------------------
tbl_summary(oasis_f2[,c(2:5,7)], by = 'CDR')
set.seed(123)
pos = sample(1:5,1)
mi.oasis_f2 = mice(oasis_f2, m=5, printFlag =FALSE)
mi.temp.oasis_f2 = complete(mi.oasis_f2,"all")
oasis_f3 = mi.temp.oasis_f2[[pos]]
attach(oasis_f3)
calc_acc = function(actual, predicted) {
mean(actual == predicted)
}
## read in data
# take 80% to be training and 20% to be testing
n = nrow(oasis_f3)
num_lst = 1:n
set.seed(123)
random_sample <- createDataPartition(num_lst, p = 0.8, list = FALSE)
Training_data = oasis_f3[random_sample,]
Testing_data = oasis_f3[-random_sample,]
ctrl <- trainControl(method = "cv", number=10, savePredictions=TRUE, classProbs=TRUE)
#Training logistic regression
set.seed(123)
glm.fit <-train(CDR~M.F+Age+Educ+SES, data=Training_data, method="glm", trControl=ctrl, tuneLength=10)
glm.TrainAcc = glm.fit$results$Accuracy
glm.TrainAcc
glm.pred=predict(glm.fit, Testing_data)
glm.TestAcc = calc_acc(predicted = glm.pred, actual = Testing_data$CDR)
glm.TestAcc
## LDA classification
library(MASS)
set.seed(123)
lda.fit <-train(CDR~M.F+Age+Educ+SES, data=Training_data, method="lda",trControl=ctrl,tuneLength=10)
#lda.Yhat = lda.fit$pred$pred
lda.pred = predict(lda.fit, Testing_data)
lda.TrainAcc = lda.fit$results$Accuracy
lda.TrainAcc
lda.TestAcc = calc_acc(predicted = lda.pred, actual = Testing_data$CDR)
lda.TestAcc
## SVM with Linear Kernel
set.seed(123)
svm.lin.fit <- train(CDR~M.F+Age+Educ+MMSE+eTIV+nWBV, data = Training_data, method = "svmLinear2", trControl = ctrl, tuneLength = 10)
#svm.lin.Yhat = svm.lin.fit$pred[svm.lin.fit$results$cost == 0.5,]$pred
svm.lin.TrainAcc = svm.lin.fit$results$Accuracy[2]
svm.lin.TrainAcc
svm.lin.pred=predict(svm.lin.fit,Testing_data)
svm.lin.TestAcc = calc_acc(predicted = svm.lin.pred, actual = Testing_data$CDR)
svm.lin.TestAcc
## SVM with Radial Kernel
set.seed(123)
svm.rad.fit <-train(CDR~M.F+Age+Educ+MMSE+eTIV+nWBV, data=Training_data, method="svmRadial",trControl=ctrl,tuneLength=10)
#svm.rad.Yhat = svm.rad.fit$pred[svm.rad.fit$results$C == 0.5,]$pred
svm.rad.TrainAcc = svm.rad.fit$results$Accuracy[2]
svm.rad.TrainAcc
svm.rad.pred=predict(svm.rad.fit,Testing_data)
svm.rad.TestAcc = calc_acc(predicted = svm.rad.pred, actual = Testing_data$CDR)
svm.rad.TestAcc
## Ramdom Forest
set.seed(123)
rf.fit <-train(CDR~M.F+Age+Educ+MMSE+eTIV+nWBV, data=Training_data, method="rf",trControl=ctrl,tuneLength=10)
rf.TrainAcc = rf.fit$results$Accuracy[2]
rf.TrainAcc
rf.pred=predict(rf.fit,Testing_data)
rf.TestAcc = calc_acc(predicted = rf.pred, actual = Testing_data$CDR)
rf.TestAcc
## SVM with Linear Kernel
set.seed(123)
svm.lin.fit <- train(CDR~M.F+Age+Educ+SES, data = Training_data, method = "svmLinear2", trControl = ctrl, tuneLength = 10)
#svm.lin.Yhat = svm.lin.fit$pred[svm.lin.fit$results$cost == 0.5,]$pred
svm.lin.TrainAcc = svm.lin.fit$results$Accuracy[2]
svm.lin.TrainAcc
svm.lin.pred=predict(svm.lin.fit,Testing_data)
svm.lin.TestAcc = calc_acc(predicted = svm.lin.pred, actual = Testing_data$CDR)
svm.lin.TestAcc
## SVM with Radial Kernel
set.seed(123)
svm.rad.fit <-train(CDR~M.F+Age+Educ+SES, data=Training_data, method="svmRadial",trControl=ctrl,tuneLength=10)
#svm.rad.Yhat = svm.rad.fit$pred[svm.rad.fit$results$C == 0.5,]$pred
svm.rad.TrainAcc = svm.rad.fit$results$Accuracy[2]
svm.rad.TrainAcc
svm.rad.pred=predict(svm.rad.fit,Testing_data)
svm.rad.TestAcc = calc_acc(predicted = svm.rad.pred, actual = Testing_data$CDR)
svm.rad.TestAcc
## Ramdom Forest
set.seed(123)
rf.fit <-train(CDR~M.F+Age+Educ+SES, data=Training_data, method="rf",trControl=ctrl,tuneLength=10)
rf.TrainAcc = rf.fit$results$Accuracy[2]
rf.TrainAcc
rf.pred=predict(rf.fit,Testing_data)
rf.TestAcc = calc_acc(predicted = rf.pred, actual = Testing_data$CDR)
rf.TestAcc
CDR_acc = data.frame(
Model = c("GLM","LDA", "SVM linear",  "SVM radial","Random Forest"),
TrainAccuracy = c(glm.TrainAcc,lda.TrainAcc, svm.lin.TrainAcc, svm.rad.TrainAcc, rf.TrainAcc),
TestAccuracy = c(glm.TestAcc,lda.TestAcc, svm.lin.TestAcc, svm.rad.TestAcc, rf.TestAcc)
)
knitr::kable(CDR_acc)
svm.lin.fit
svm.rad.fit$results$Accuracy
svm.rad.fit
rf.fit
## GLMNET
set.seed(123)
glmnet.fit <-train(CDR~M.F+Age+Educ+SES, data=Training_data, method="glmnet",trControl=ctrl,tuneLength=10)
glmnet.fit
## read in data
# take 80% to be training and 20% to be testing
n = nrow(oasis_f3)
num_lst = 1:n
set.seed(123)
random_sample <- createDataPartition(num_lst, p = 0.8, list = FALSE)
Training_data = oasis_f3[random_sample,]
Testing_data = oasis_f3[-random_sample,]
ctrl <- trainControl(method = "cv", number=10, savePredictions=TRUE, classProbs=TRUE)
#Training logistic regression
set.seed(123)
glm.fit <-train(CDR~M.F+Age+Educ+SES, data=Training_data, method="glm", trControl=ctrl, tuneLength=10)
glm.TrainAcc = glm.fit$results$Accuracy
glm.TrainAcc
glm.pred=predict(glm.fit, Testing_data)
glm.TestAcc = calc_acc(predicted = glm.pred, actual = Testing_data$CDR)
glm.TestAcc
## LDA classification
set.seed(123)
lda.fit <-train(CDR~M.F+Age+Educ+SES, data=Training_data, method="lda",trControl=ctrl,tuneLength=10)
#lda.Yhat = lda.fit$pred$pred
lda.pred = predict(lda.fit, Testing_data)
lda.TrainAcc = lda.fit$results$Accuracy
lda.TrainAcc
lda.TestAcc = calc_acc(predicted = lda.pred, actual = Testing_data$CDR)
lda.TestAcc
## SVM with Linear Kernel
set.seed(123)
svm.lin.fit <- train(CDR~M.F+Age+Educ+SES, data = Training_data, method = "svmLinear2", trControl = ctrl, tuneLength = 10)
#svm.lin.Yhat = svm.lin.fit$pred[svm.lin.fit$results$cost == 0.5,]$pred
svm.lin.TrainAcc = max(svm.lin.fit$results$Accuracy)
svm.lin.TrainAcc
svm.lin.pred=predict(svm.lin.fit,Testing_data)
svm.lin.TestAcc = calc_acc(predicted = svm.lin.pred, actual = Testing_data$CDR)
svm.lin.TestAcc
## SVM with Radial Kernel
set.seed(123)
svm.rad.fit <-train(CDR~M.F+Age+Educ+SES, data=Training_data, method="svmRadial",trControl=ctrl,tuneLength=10)
#svm.rad.Yhat = svm.rad.fit$pred[svm.rad.fit$results$C == 0.5,]$pred
svm.rad.TrainAcc = max(svm.rad.fit$results$Accuracy)
svm.rad.TrainAcc
svm.rad.pred=predict(svm.rad.fit,Testing_data)
svm.rad.TestAcc = calc_acc(predicted = svm.rad.pred, actual = Testing_data$CDR)
svm.rad.TestAcc
## Ramdom Forest
set.seed(123)
rf.fit <-train(CDR~M.F+Age+Educ+SES, data=Training_data, method="rf",trControl=ctrl,tuneLength=10)
rf.TrainAcc = max(rf.fit$results$Accuracy)
rf.TrainAcc
rf.pred=predict(rf.fit,Testing_data)
rf.TestAcc = calc_acc(predicted = rf.pred, actual = Testing_data$CDR)
rf.TestAcc
## GLMNET
set.seed(123)
glmnet.fit <-train(CDR~M.F+Age+Educ+SES, data=Training_data, method="glmnet",trControl=ctrl,tuneLength=10)
# alpha = 1 and lambda = 0.04241753
glmnet.TrainAcc = max(glmnet.fit$results$Accuracy)
glmnet.TrainAcc
glmnet.pred=predict(glmnet.fit,Testing_data)
glmnet.TestAcc = calc_acc(predicted = glmnet.pred, actual = Testing_data$CDR)
glmnet.TestAcc
CDR_acc = data.frame(
Model = c("GLM","LDA", "SVM linear",  "SVM radial","Random Forest", "glmnet"),
TrainAccuracy = c(glm.TrainAcc,lda.TrainAcc, svm.lin.TrainAcc, svm.rad.TrainAcc, rf.TrainAcc,glmnet.TrainAcc ),
TestAccuracy = c(glm.TestAcc,lda.TestAcc, svm.lin.TestAcc, svm.rad.TestAcc, rf.TestAcc,glmnet.TestAcc)
)
knitr::kable(CDR_acc)
glm_out1 <- lasso.fit %>%
augment() %>%
mutate(model = "m1") # name the model
library(dplyr)
glm_out1 <- lasso.fit %>%
augment() %>%
mutate(model = "m1") # name the model
load("../data/img_list.rds")
library(ggplot2)
library(randomForest)
library(klaR)
library(MASS)
library(e1071)
library(caret)
library(dplyr)
S.new <- array (NA, dim = c(176,208,length(img_list)))
for (i in 1:length(img_list)){
a = img_list[[i]]
test = a[,,88]
S.new[,,i] = test
}
data = read.csv("../data/oasis_cross-sectional_filter.csv")
labels = data$CDR
n = nrow(S.new)
num_lst = 1:n
set.seed(123)
random_sample <- createDataPartition(num_lst, p = 0.8, list = FALSE)
train.X = S.new[,,random_sample]
test.X = S.new[,,-random_sample]
data$CDR = as.factor(data$CDR)
levels(data$CDR) <- c("EqaulTo0", "LargeThan0")
train.demo = data[random_sample,]
test.demo = data[-random_sample,]
train.Y = as.numeric(train.demo$CDR)-1
test.Y = as.numeric(test.demo$CDR)-1
prep_binary_classification = function(images, labels, posLabel = 1, negLabel = 0) {
dims = dim(images)
X.pos = t(matrix(images[,,labels %in% posLabel],nrow=dims[1]*dims[2])) ## n1 * 36608
X.neg = t(matrix(images[,,labels %in% negLabel],nrow=dims[1]*dims[2])) ## n1 * 36608
return(list(X=rbind(X.pos, X.neg),y = c(rep(1,nrow(X.pos)),rep(0,nrow(X.neg)))))
}
trn = prep_binary_classification(train.X, train.Y, 1, 0)
tst = prep_binary_classification(test.X, test.Y, 1, 0)
pca.X =prcomp(trn$X)
trn_X <- predict(pca.X, newdata = trn$X)
tst_X <- predict(pca.X, newdata =tst$X)
Training_data <- cbind.data.frame(y=train.demo$CDR,trn_X)
Testing_data <- cbind.data.frame(y=test.demo$CDR,tst_X)
True_cdr = as.numeric(Testing_data$y)-1
calc_acc = function(actual, predicted) {
mean(actual == predicted)
}
ctrl <- trainControl(method = "cv", number=10, savePredictions=TRUE, classProbs=TRUE, allowParallel = T,verboseIter = T)
## LDA classification
library(MASS)
set.seed(123)
lda.fit <-train(x = Training_data[,-1], y = Training_data$y, data = Training_data, method="sparseLDA",trControl=ctrl,tuneLength=10)
#lda.Yhat = lda.fit$pred$pred
lda.pred = predict(lda.fit, Testing_data)
lda.TrainAcc = max(na.omit(lda.fit$results$Accuracy))
lda.TestAcc = calc_acc(predicted = lda.pred, actual = Testing_data$y)
lda.cfmat = table(Prediction = lda.pred, Reference = True_cdr)
lda.res = list(lda.fit=lda.fit,lda.TrainAcc=lda.TrainAcc,lda.TestAcc=lda.TestAcc,lda.cfmat=lda.cfmat)
lda.res
## SVM with Linear Kernel
set.seed(123)
svm.lin.fit <- train(y~., data = Training_data, method = "svmLinear2", trControl = ctrl, tuneLength = 10)
#svm.lin.Yhat = svm.lin.fit$pred[svm.lin.fit$results$cost == 0.5,]$pred
svm.lin.TrainAcc = max(svm.lin.fit$results["Accuracy"])
svm.lin.pred=predict(svm.lin.fit,Testing_data)
svm.lin.TestAcc = calc_acc(predicted = svm.lin.pred, actual = Testing_data$y)
svm.lin.cfmat = table(Prediction = svm.lin.pred, Reference = True_cdr)
svm.lin.res = list(svm.lin.fit=svm.lin.fit,svm.lin.TrainAcc=svm.lin.TrainAcc,svm.lin.TestAcc=svm.lin.TestAcc)
svm.lin.res
## SVM with Radial Kernel
set.seed(123)
svm.rad.fit <-train(y~., data = Training_data, method="svmRadial",trControl=ctrl,tuneLength=10)
#svm.rad.Yhat = svm.rad.fit$pred[svm.rad.fit$results$C == 0.5,]$pred
svm.rad.TrainAcc = max(svm.rad.fit$results["Accuracy"])
svm.rad.pred=predict(svm.rad.fit,Testing_data)
svm.rad.TestAcc = calc_acc(predicted = svm.rad.pred, actual = Testing_data$y)
svm.rad.cfmat = table(Prediction = svm.rad.pred, Reference = True_cdr)
svm.rad.res = list(svm.rad.fit=svm.rad.fit,svm.rad.TrainAcc=svm.rad.TrainAcc,svm.rad.TestAcc=svm.rad.TestAcc,svm.rad.cfmat=svm.rad.cfmat)
svm.rad.res
# ## SVM with Polynomial Kernel
# set.seed(123)
# svm.ply.fit <-train(y~., data = Training_data, method="svmPoly",trControl=ctrl,tuneLength=10)
# #svm.ply.Yhat = svm.ply.fit$pred[svm.ply.fit$results$C == 0.5,]$pred
# svm.ply.TrainAcc = max(svm.ply.fit$results["Accuracy"])
# svm.ply.pred=predict(svm.ply.fit,Testing_data)
# svm.ply.TestAcc = calc_acc(predicted = svm.ply.pred, actual = Testing_data$y)
#
# svm.ply.res = list(svm.ply.fit=svm.ply.fit,svm.ply.TrainAcc=svm.ply.TrainAcc,svm.ply.TestAcc=svm.ply.TestAcc)
# svm.ply.res
## Ramdom Forest
set.seed(123)
rf.fit <-train(y~., data = Training_data, method="rf",trControl=ctrl,tuneLength=10)
rf.TrainAcc = max(rf.fit$results["Accuracy"])
rf.pred=predict(rf.fit,Testing_data)
rf.TestAcc = calc_acc(predicted = rf.pred, actual = Testing_data$y)
rf.cfmat = table(Prediction = rf.pred, Reference = True_cdr)
rf.res = list(rf.fit=rf.fit,rf.TrainAcc=rf.TrainAcc,rf.TestAcc=rf.TestAcc,rf.cfmat=rf.cfmat)
rf.res
# ## Naive Bayes
# set.seed(123)
# nb.fit <-train(y~., data = Training_data, method="nb",trControl=ctrl,tuneLength=10)
#
# nb.TrainAcc = max(nb.fit$results["Accuracy"])
# nb.pred=predict(nb.fit,Testing_data)
# nb.TestAcc = calc_acc(predicted = nb.pred, actual = Testing_data$y)
#
# nb.res = list(nb.fit=nb.fit,nb.TrainAcc=nb.TrainAcc,nb.TestAcc=nb.TestAcc)
# nb.res
result = list(svm.lin.res = svm.lin.res,svm.rad.res = svm.rad.res,rf.res=rf.res)
CDR_acc = data.frame(
Model = c("LDA", "SVM linear",  "SVM radial","Random Forest"),
TrainAccuracy = c(lda.TrainAcc, svm.lin.TrainAcc, svm.rad.TrainAcc, rf.TrainAcc),
TestAccuracy = c(lda.TestAcc, svm.lin.TestAcc, svm.rad.TestAcc, rf.TestAcc)
)
knitr::kable(CDR_acc)
save(result, file ="SVM_RF_ImgOnly_result.rds")
data = read.csv("../data/oasis_cross-sectional_filter.csv")
load("../data/img_list.rds")
load("./data/img_list.rds")
library(ggplot2)
library(randomForest)
library(klaR)
library(MASS)
library(e1071)
library(caret)
library(dplyr)
S.new <- array (NA, dim = c(176,208,length(img_list)))
for (i in 1:length(img_list)){
a = img_list[[i]]
test = a[,,88]
S.new[,,i] = test
}
data = read.csv("./data/oasis_cross-sectional_filter.csv")
labels = data$CDR
n = nrow(S.new)
num_lst = 1:n
set.seed(123)
random_sample <- createDataPartition(num_lst, p = 0.8, list = FALSE)
train.X = S.new[,,random_sample]
test.X = S.new[,,-random_sample]
data$CDR = as.factor(data$CDR)
levels(data$CDR) <- c("EqaulTo0", "LargeThan0")
train.demo = data[random_sample,]
test.demo = data[-random_sample,]
train.Y = as.numeric(train.demo$CDR)-1
test.Y = as.numeric(test.demo$CDR)-1
prep_binary_classification = function(images, labels, posLabel = 1, negLabel = 0) {
dims = dim(images)
X.pos = t(matrix(images[,,labels %in% posLabel],nrow=dims[1]*dims[2])) ## n1 * 36608
X.neg = t(matrix(images[,,labels %in% negLabel],nrow=dims[1]*dims[2])) ## n1 * 36608
return(list(X=rbind(X.pos, X.neg),y = c(rep(1,nrow(X.pos)),rep(0,nrow(X.neg)))))
}
trn = prep_binary_classification(train.X, train.Y, 1, 0)
tst = prep_binary_classification(test.X, test.Y, 1, 0)
pca.X =prcomp(trn$X)
trn_X <- predict(pca.X, newdata = trn$X)
tst_X <- predict(pca.X, newdata =tst$X)
Training_data <- cbind.data.frame(y=train.demo$CDR,trn_X)
Testing_data <- cbind.data.frame(y=test.demo$CDR,tst_X)
True_cdr = as.numeric(Testing_data$y)-1
calc_acc = function(actual, predicted) {
mean(actual == predicted)
}
ctrl <- trainControl(method = "cv", number=10, savePredictions=TRUE, classProbs=TRUE, allowParallel = T,verboseIter = T)
## LDA classification
library(MASS)
set.seed(123)
lda.fit <-train(x = Training_data[,-1], y = Training_data$y, data = Training_data, method="sparseLDA",trControl=ctrl,tuneLength=10)
#lda.Yhat = lda.fit$pred$pred
lda.pred = predict(lda.fit, Testing_data)
lda.TrainAcc = max(na.omit(lda.fit$results$Accuracy))
lda.TestAcc = calc_acc(predicted = lda.pred, actual = Testing_data$y)
lda.cfmat = table(Prediction = lda.pred, Reference = True_cdr)
lda.res = list(lda.fit=lda.fit,lda.TrainAcc=lda.TrainAcc,lda.TestAcc=lda.TestAcc,lda.cfmat=lda.cfmat)
lda.res
## SVM with Linear Kernel
set.seed(123)
svm.lin.fit <- train(y~., data = Training_data, method = "svmLinear2", trControl = ctrl, tuneLength = 10)
#svm.lin.Yhat = svm.lin.fit$pred[svm.lin.fit$results$cost == 0.5,]$pred
svm.lin.TrainAcc = max(svm.lin.fit$results["Accuracy"])
svm.lin.pred=predict(svm.lin.fit,Testing_data)
svm.lin.TestAcc = calc_acc(predicted = svm.lin.pred, actual = Testing_data$y)
svm.lin.cfmat = table(Prediction = svm.lin.pred, Reference = True_cdr)
svm.lin.res = list(svm.lin.fit=svm.lin.fit,svm.lin.TrainAcc=svm.lin.TrainAcc,svm.lin.TestAcc=svm.lin.TestAcc)
svm.lin.res
## SVM with Radial Kernel
set.seed(123)
svm.rad.fit <-train(y~., data = Training_data, method="svmRadial",trControl=ctrl,tuneLength=10)
#svm.rad.Yhat = svm.rad.fit$pred[svm.rad.fit$results$C == 0.5,]$pred
svm.rad.TrainAcc = max(svm.rad.fit$results["Accuracy"])
svm.rad.pred=predict(svm.rad.fit,Testing_data)
svm.rad.TestAcc = calc_acc(predicted = svm.rad.pred, actual = Testing_data$y)
svm.rad.cfmat = table(Prediction = svm.rad.pred, Reference = True_cdr)
svm.rad.res = list(svm.rad.fit=svm.rad.fit,svm.rad.TrainAcc=svm.rad.TrainAcc,svm.rad.TestAcc=svm.rad.TestAcc,svm.rad.cfmat=svm.rad.cfmat)
svm.rad.res
# ## SVM with Polynomial Kernel
# set.seed(123)
# svm.ply.fit <-train(y~., data = Training_data, method="svmPoly",trControl=ctrl,tuneLength=10)
# #svm.ply.Yhat = svm.ply.fit$pred[svm.ply.fit$results$C == 0.5,]$pred
# svm.ply.TrainAcc = max(svm.ply.fit$results["Accuracy"])
# svm.ply.pred=predict(svm.ply.fit,Testing_data)
# svm.ply.TestAcc = calc_acc(predicted = svm.ply.pred, actual = Testing_data$y)
#
# svm.ply.res = list(svm.ply.fit=svm.ply.fit,svm.ply.TrainAcc=svm.ply.TrainAcc,svm.ply.TestAcc=svm.ply.TestAcc)
# svm.ply.res
## Ramdom Forest
set.seed(123)
rf.fit <-train(y~., data = Training_data, method="rf",trControl=ctrl,tuneLength=10)
rf.TrainAcc = max(rf.fit$results["Accuracy"])
rf.pred=predict(rf.fit,Testing_data)
rf.TestAcc = calc_acc(predicted = rf.pred, actual = Testing_data$y)
rf.cfmat = table(Prediction = rf.pred, Reference = True_cdr)
rf.res = list(rf.fit=rf.fit,rf.TrainAcc=rf.TrainAcc,rf.TestAcc=rf.TestAcc,rf.cfmat=rf.cfmat)
rf.res
# ## Naive Bayes
# set.seed(123)
# nb.fit <-train(y~., data = Training_data, method="nb",trControl=ctrl,tuneLength=10)
#
# nb.TrainAcc = max(nb.fit$results["Accuracy"])
# nb.pred=predict(nb.fit,Testing_data)
# nb.TestAcc = calc_acc(predicted = nb.pred, actual = Testing_data$y)
#
# nb.res = list(nb.fit=nb.fit,nb.TrainAcc=nb.TrainAcc,nb.TestAcc=nb.TestAcc)
# nb.res
result = list(svm.lin.res = svm.lin.res,svm.rad.res = svm.rad.res,rf.res=rf.res)
CDR_acc = data.frame(
Model = c("LDA", "SVM linear",  "SVM radial","Random Forest"),
TrainAccuracy = c(lda.TrainAcc, svm.lin.TrainAcc, svm.rad.TrainAcc, rf.TrainAcc),
TestAccuracy = c(lda.TestAcc, svm.lin.TestAcc, svm.rad.TestAcc, rf.TestAcc)
)
knitr::kable(CDR_acc)
save(result, file ="SVM_RF_ImgOnly_result.rds")
result = list(svm.lin.res = svm.lin.res,svm.rad.res = svm.rad.res,rf.res=rf.res,CDR_acc=CDR_acc)
save(result, file ="SVM_RF_ImgOnly_result.rds")
SVM_RF_ImgOnly_result <- readRDS("C:/Users/xtk96/Desktop/625OASIS/SVM_RF_ImgOnly_result.rds")
result
save(result, file ="SVM_RF_ImgOnly_result.Rdata")
load("C:/Users/xtk96/Desktop/625OASIS/SVM_RF_ImgOnly_result.Rdata")
save(result, file ="./result/SVM_RF_ImgOnly_result.Rdata")
load("C:/Users/xtk96/Desktop/625OASIS/result/SVM_RF_ImgOnly_result.Rdata")
View(result)
result = list(lda.res = lda.res, svm.lin.res = svm.lin.res,svm.rad.res = svm.rad.res,rf.res=rf.res,CDR_acc=CDR_acc)
save(result, file ="./result/SVM_RF_ImgOnly_result.Rdata")
load("C:/Users/xtk96/Desktop/625OASIS/result/SVM_RF_ImgOnly_result.Rdata")
View(result)
SVM_RF_ImgOnly_result = list(lda.res = lda.res, svm.lin.res = svm.lin.res,svm.rad.res = svm.rad.res,rf.res=rf.res,CDR_acc=CDR_acc)
save(SVM_RF_ImgOnly_result, file ="./result/SVM_RF_ImgOnly_result.Rdata")
load("C:/Users/xtk96/Desktop/625OASIS/result/SVM_RF_ImgOnly_result.Rdata")
View(SVM_RF_ImgOnly_result)
library(foreign)
library(ggplot2)
library(reshape2)
library(dplyr)
library(lme4)
skin_dt = read.dta("C:/Users/xtk96/Desktop/data/skin.dta")
skin_dt$gender = factor(skin_dt$gender)
skin_dt$skin = factor(skin_dt$skin)
skin_dt$trt = factor(skin_dt$trt)
model1 = glmer(y ~ year + trt:year +(1|id), data=skin_dt, family=poisson, nAGQ = 50, na.action=na.omit)
summary(model1)
model2 = glmer(y ~ year + trt:year +skin+age+exposure+(1|id), data=skin_dt, family=poisson, nAGQ = 50, na.action=na.omit)
summary(model2)
