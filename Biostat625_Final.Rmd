
---
title: "Predicting Dementia Diagnosis with Neuroimaging Data"
author: "Boya Jiang,Chen Chen,Tiankai Xie,Yuan Zhong"
date: "12/15/2021"
output: pdf_document
---
# Introduction  
Alzheimer’s is a dementia degenerative disease starting with mild memory impairment in the early stages and progressing to a complete loss of the mental and physical faculties [1]. Definitive Alzheimer's Disease (AD) diagnosis relies on a magnetic resonance image (MRI) study. Brain MRI scans are detailed three-dimensional anatomical images, and changes in the hippocampus, frontal and parietal regions are evidential markers in the progress of AD. The ability to diagnose and classify AD at an early stage allows clinicians to make more knowledgeable decisions regarding clinical interventions. In this project, we apply multiple representative methods to predict Alzheimer's status.  

# Data and Preprocessing
OASIS (Open Access Series of Imaging Studies) is a well-known initiative that is publicly available for study and analysis. The present MRI dataset, OASIS-I (presented in 2007) [2], is a cross-sectional collection of data for 416 participants aged 18-96 yrs, 316 non-demented and 100 at various stages of AD. Subjects were characterized by the Clinical Dementia Rating (CDR) scale from cognitive normal (CDR = 0), very-mild dementia (CDR = 0.5) to mild dementia (CDR = 1). The data set also contains the following demographics information: male/female, age, education (Educ), and socioeconomic status (SES). Data set of MRI scans of axial plane contains 176 slices/images of 176 x 208 pixel size.  

Since AD is more prevalent among older adults, we selected individuals between 60 and 96 years old. The CDR was dichotomized to 0 for cognitive normal (CN), and 1 for any level of dementia. Our final sample composed of 198 individuals, which were randomly split into two groups in 80:20 ratios as training and testing sets, respectively. In our variable of interest, there does not exist data formatting problem, but there is a missing data problem in SES, with 18 missing records. By using predictive mean matching as imputation method from mice package,  missing data problem is solved. Table 1 shows a summary of demographic variables collected for CN and dementia groups. The training and testing sets had balanced CDR distribution. Figure 1 shows a comparison of MRI scan between a CN patient and a dementia patient at the same slice.  
```{r, echo = F, message=F}
load('./tables and figures/summary_afterImp')
sum_tb_after_imp
```

# Methods
```{r,echo=FALSE,out.height = '120px', fig.cap="MRI scan of CN (left) and dementia (right) patients", fig.align='center'}
knitr::include_graphics(c("./tables and figures/MRI.png"))     
```

In order to classify dementia from CN, we applied the following five methods: penalized logistic regression (ridge and lasso), random forest, support vector machine (linear and radial kernel), native Bayes, and convolutional neural network (CNN).  

**Data Preperation**
In order to prepare data for all 3D methods (a to d), we selected the middle slice for each patient, creating an array of dimensions 176 x 208 x 198. Next, to improve the speed of model analysis, data was further cleaned by removing axes containing all zero values. For logistic regression, parameter tuning was performed through 10-fold cross-validation analysis via ``cv.glmnet()``. For random forest, SVM, and native Bayes, principal component analysis (PCA) was performed for feature extraction prior to model fitting. In addition, parameter tuning was performed through 10-fold cross-validation analysis via ``caret::trainControl()``, which controls parameters for train data. For methods a) to d), models were fit on neuroimaging data with and without demographic variables.  

**a) Logistic Regression (LR)**  
Logistic regression was preferred over linear discriminant analysis (LDA) because it does not require the independent variables to satisfy the assumptions of linearity, normal distribution, or equal variance. LR also provides a deterministic model yielding weighting factors for each contributing variable, while avoiding overfitting the data. Both ridge and lasso methods were used for regularization.  

**b) Random Forest (RF)**   
Random forest is an ensemble learning method. For classification tasks, its output is the class selected by most trees. It doesn't overfit with more features and its efficiency is particularly notable in large data sets. The random forest method was called from ``randomForest``.

<<<<<<< HEAD
**c) support Vector Machine (SVM)**   
=======
**c) Support Vector Machine (SVM)**   
>>>>>>> 8455cd3fd0d13eb2f095a1e2fb2e3e262c5cb930
Support vector machine is a supervised learning method. It is effective in high dimensional spaces and in cases where number of dimensions is greater than the number of samples. It is also memory efficient since it uses a subset of training points in the decision function, known as support vectors. Both linear and radial kernel were used for regularization. The SVM with linear kernel was called from  ``e1071`` and the SVM with radial kernel was called from ``kernlab``.  

**d) Naive Bayes**  
Naive Bayes is a  classifier based on applying Bayes' theorem with strong independence assumptions between the features. It coupled simple Bayesian network models with kernel density estimation, and can achieve higher accuracy levels.Unlike ther types of classifiers wihch use expensive iterative approximation, its maximum-likelihood training can be done by evaluating a closed-form expression, which only takes linear time. The Naive Bayes was called from ``klaR``.


**e) CNN**   


# Deliverable and Code Repository
### Shiny App
Shiny Application We built our Shiny application using the ridge LR as our classifier embedded behind the dashboard. This means that the dashboard can take patients MRI data and some demographic and clinical input to predicts of Dementia diagnosis using CNN model. The Shiny application can be viewed by running this command, shiny::runGitHub('625OASIS','y1zhong', subdir = 'shiny'), on the R console. Packages like Shiny and oro.nifti must be installed before this app can be run.
 
### GitHub
A GitHub repository is created to store, update, display, and share the results of our project. Here is the link: https://github.com/y1zhong/625OASIS

# Challenges 



# Evaluation

To evaluate the performance of each model, we compared test sensitivity, specificity, and accuracy (Table 2). When only image data was included in the model, the best classification model was Ridge regression with the highest accuracy (0.79), sensitivity (0.75), and specificity (0.83). Figure 2 presented the ROC curve for each model which also indicated that Ridge regression was the best model to predict Alzheimer dementia. Lasso regression also performed well with a relative high accuracy that correctly classified 68% of the MRI. However, RF and LDA had a higher sensitivity than Lasso regression (0.65 and 0.63 respectively). The purpose of our analysis was to correctly predict AD, so sensitivity was more important than accuracy which indicated the percentage of true positive among test cases. We further included demographic information in our models, but the performance of prediction was not improved and some RF even had 28% decrease in sensitivity. 

```{r, echo=FALSE}
library(knitr)
# library(kableExtra)
load("./tables and figures/result_table.RData")
knitr::kable(result_table, align="c", col.names = NULL)
      # caption = "Table 2 Performance of models in sensitivity, specificity, and accuracy")
```



# Discussion

In conclusion, we compared the prediction of multiple classification models, and the Ridge regression outperformed others in terms of accuracy, sensitivity, and specificity. Comparing to literature, our analyses had several important strengths. Some literature may have outstanding accuracy that is more than 95% when comparing MRI of Alzheimer's dementia with healthy control in young adults. However, young adults were not at risk of developing AD and using their MRI as control would introduce bias and over predict the result. Our analysis only included older adults which would be more practical to distinguish AD and healthy aging brain. Secondly, our outcome AD was balanced among cases and controls which would increase our accuracy. However, accuracy of AD prediction was different by the stages of AD. Since there were no significant symptoms at early AD stage when the degeneration of the brain had begun, it was difficult to diagnosis AD and more likely to discover AD at later stages. Therefore, accuracy would be differentiated by the level of comparison and distinguishing MCI from healthy aging would be the most difficult. Past classification models showed much lower accuracy between 40% to 60%. In our analysis, we combined MCI, AD, and severe AD as one group which made prediction harder with lower accuracy. Our CNN method was the most challenging model as it not only required large sample size, but also advanced computing environment such as cluster computing or GPU computing to incorporate the high-dimensional structure. Many research teams already recruited extraordinary engineers and computer science expertise to improve the algorithm, but with less focus on important biomarkers of AD such as APOE and CSF and other important clinical information. Future research should consider including more biostatistics, neurology, and epidemiology field to create multi-disciplinary research.  

# Contributions


# References
1. Alzheimer’s Association. 2016 Alzheimer’s disease facts and figures. Alzheimer’s Dementia. 2016, 12, 459–509.
2. Open Access Series of Imaging Studies (OASIS): Cross-Sectional MRI Data in Young, Middle Aged, Nondemented, and Demented Older Adults. Marcus, DS, Wang, TH, Parker, J, Csernansky, JG, Morris, JC, Buckner, RL. Journal of Cognitive Neuroscience, 19, 1498-1507. doi: 10.1162/jocn.2007.19.9.1498. 


